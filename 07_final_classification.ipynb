{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "15bce37d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents utilisés: 285\n"
     ]
    }
   ],
   "source": [
    "import os, glob, re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix, lil_matrix, hstack\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "from sklearn.metrics import classification_report, precision_recall_fscore_support\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "TXT=\"TXT\"; TTG=\"TTG\"; FLEMM=\"FLEMM\"; REL=\"RELH2-TP\"; HDT=\"HDT-TP\"; META=\"METADATA3\"\n",
    "\n",
    "valid=[]\n",
    "for f in glob.glob(f\"{TXT}/*.txt\"):\n",
    "    doc=os.path.basename(f).replace(\".txt\",\"\")\n",
    "    if doc!=\"termlist\" and os.path.exists(f\"{TTG}/{doc}.ttg\") and os.path.exists(f\"{META}/{doc}_md.txt\"):\n",
    "        valid.append(doc)\n",
    "\n",
    "valid=sorted(valid)\n",
    "print(\"Documents utilisés:\",len(valid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "dfdfcb7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_bow = (285, 6528)\n"
     ]
    }
   ],
   "source": [
    "raw=[\" \".join(open(f\"{TXT}/{d}.txt\").read().split()) for d in valid]\n",
    "\n",
    "bow = CountVectorizer(min_df=2, ngram_range=(1,2))\n",
    "X_bow = bow.fit_transform(raw)\n",
    "print(\"X_bow =\",X_bow.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b9e6d903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_ttg = (285, 5717)\n"
     ]
    }
   ],
   "source": [
    "vocab_ttg={}; data=[]; idx=[]; ptr=[0]\n",
    "\n",
    "for d in valid:\n",
    "    df=pd.read_csv(f\"{TTG}/{d}.ttg\",sep=\"\\t\",header=None).astype(str)\n",
    "    tokens=list(df[0])+list(df[2])  # forme + lemme\n",
    "    for t in tokens:\n",
    "        j=vocab_ttg.setdefault(t,len(vocab_ttg))\n",
    "        idx.append(j); data.append(1)\n",
    "    ptr.append(len(idx))\n",
    "\n",
    "X_ttg = csr_matrix((data,idx,ptr))\n",
    "print(\"X_ttg =\",X_ttg.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4f2e9cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_flemm = (285, 95)\n"
     ]
    }
   ],
   "source": [
    "lemmas=[]\n",
    "for d in valid:\n",
    "    words=[]\n",
    "    for line in open(f\"{FLEMM}/{d}.flemm\",encoding=\"utf-8\"):\n",
    "        cols=line.strip().split(\"\\t\")\n",
    "        if len(cols)>=2: words.append(cols[1])\n",
    "    lemmas.append(\" \".join(words))\n",
    "\n",
    "fv = CountVectorizer(min_df=2)\n",
    "X_flemm = fv.fit_transform(lemmas)\n",
    "print(\"X_flemm =\",X_flemm.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4c78b2b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_rel = (285, 7)\n"
     ]
    }
   ],
   "source": [
    "X_rel=lil_matrix((len(valid),4000))\n",
    "hv={};col=0\n",
    "\n",
    "for i,d in enumerate(valid):\n",
    "    f=f\"{REL}/{d}.relH2\"\n",
    "    if os.path.exists(f):\n",
    "        for line in open(f,encoding=\"utf-8\"):\n",
    "            if \"\\t\" in line:\n",
    "                h,y=line.split(\"\\t\")\n",
    "                H=y.replace(\"/term\",\"\").strip()\n",
    "                if H not in hv: hv[H]=col; col+=1\n",
    "                X_rel[i,hv[H]]=1\n",
    "\n",
    "X_rel=X_rel[:,:col].tocsr()\n",
    "print(\"X_rel =\",X_rel.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3ccdfb37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_hdt = (285, 1)\n"
     ]
    }
   ],
   "source": [
    "X_hdt=lil_matrix((len(valid),50))\n",
    "hdt_map={};cid=0\n",
    "\n",
    "for i,d in enumerate(valid):\n",
    "    f=f\"{HDT}/{d}.hdt\"    # adapte extension si .ann/.txt\n",
    "    if os.path.exists(f):\n",
    "        for line in open(f):\n",
    "            if \"TIMEX3\" in line:\n",
    "                if \"TIME\" not in hdt_map: hdt_map[\"TIME\"]=cid;cid+=1\n",
    "                X_hdt[i,hdt_map[\"TIME\"]]=1\n",
    "            if \"DIST\" in line:\n",
    "                if \"DIST\" not in hdt_map: hdt_map[\"DIST\"]=cid;cid+=1\n",
    "                X_hdt[i,hdt_map[\"DIST\"]]=1\n",
    "            if \"SPEED\" in line:\n",
    "                if \"SPEED\" not in hdt_map: hdt_map[\"SPEED\"]=cid;cid+=1\n",
    "                X_hdt[i,hdt_map[\"SPEED\"]]=1\n",
    "\n",
    "X_hdt=X_hdt[:,:cid].tocsr()\n",
    "print(\"X_hdt =\",X_hdt.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9bdf6ad6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_ani = (285, 3)\n"
     ]
    }
   ],
   "source": [
    "ani=[];dist=[];speed=[]\n",
    "\n",
    "r_animal  = r\"(rapace|aigle|chauve[- ]?souris|goéland|oiseau|mouette|corbeau)\"\n",
    "r_dist    = r\"\\b\\d{1,4} ?m\\b\"\n",
    "r_speed   = r\"\\b\\d{1,3} ?(km/h|m/s)\\b\"\n",
    "\n",
    "for d in valid:\n",
    "    txt=open(f\"{TXT}/{d}.txt\").read().lower()\n",
    "    ani.append(int(bool(re.search(r_animal,txt))))\n",
    "    dist.append(int(bool(re.search(r_dist,txt))))\n",
    "    speed.append(int(bool(re.search(r_speed,txt))))\n",
    "\n",
    "X_ani = csr_matrix(np.vstack([ani,dist,speed]).T)\n",
    "print(\"X_ani =\",X_ani.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "694b24d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf = TfidfTransformer(sublinear_tf=True)\n",
    "X_bow_tfidf   = tfidf.fit_transform(X_bow)\n",
    "X_flemm_tfidf = tfidf.fit_transform(X_flemm)\n",
    "X_ttg_tfidf   = tfidf.fit_transform(X_ttg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "be36c28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "def svd_reduce(X, n=200):\n",
    "    n_comp = min(n, X.shape[1]-1)   # <-- sécurité automatique\n",
    "    return TruncatedSVD(n_components=n_comp, random_state=0).fit_transform(X)\n",
    "\n",
    "X_svd_bow   = svd_reduce(X_bow_tfidf,   n=250)   # gros → 250 OK\n",
    "X_svd_flemm = svd_reduce(X_flemm_tfidf, n=80)    # 95 → mettra 94\n",
    "X_svd_ttg   = svd_reduce(X_ttg_tfidf,   n=120)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "236d0535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_boost: (285, 461)\n"
     ]
    }
   ],
   "source": [
    "X_boost = np.hstack([\n",
    "    X_svd_bow,\n",
    "    X_svd_flemm,\n",
    "    X_svd_ttg,\n",
    "    X_rel.toarray(),\n",
    "    X_hdt.toarray(),\n",
    "    X_ani.toarray()\n",
    "])\n",
    "\n",
    "print(\"X_boost:\",X_boost.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "160cb6b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== SVM optimized ========\n",
      "                                                                               precision    recall  f1-score   support\n",
      "\n",
      "                                               CONSÉQUENCES ENVIRONNEMENTALES      0.972     0.955     0.963       110\n",
      "                                                     CONSÉQUENCES ÉCONOMIQUES      0.516     0.653     0.576        75\n",
      "                      CONSÉQUENCES ÉCONOMIQUES,CONSÉQUENCES ENVIRONNEMENTALES      0.333     0.231     0.273        13\n",
      "                               CONSÉQUENCES ÉCONOMIQUES,CONSÉQUENCES SOCIALES      0.462     0.462     0.462        39\n",
      "CONSÉQUENCES ÉCONOMIQUES,CONSÉQUENCES SOCIALES,CONSÉQUENCES ENVIRONNEMENTALES      0.000     0.000     0.000         6\n",
      "                                                                     Inconnue      0.412     0.333     0.368        42\n",
      "\n",
      "                                                                     accuracy                          0.663       285\n",
      "                                                                    macro avg      0.449     0.439     0.440       285\n",
      "                                                                 weighted avg      0.650     0.663     0.653       285\n",
      "\n",
      "Macro-F = 0.4404100212376975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/lib/python3/dist-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== RF optimized ========\n",
      "                                                                               precision    recall  f1-score   support\n",
      "\n",
      "                                               CONSÉQUENCES ENVIRONNEMENTALES      0.972     0.964     0.968       110\n",
      "                                                     CONSÉQUENCES ÉCONOMIQUES      0.437     0.973     0.603        75\n",
      "                      CONSÉQUENCES ÉCONOMIQUES,CONSÉQUENCES ENVIRONNEMENTALES      0.000     0.000     0.000        13\n",
      "                               CONSÉQUENCES ÉCONOMIQUES,CONSÉQUENCES SOCIALES      0.556     0.128     0.208        39\n",
      "CONSÉQUENCES ÉCONOMIQUES,CONSÉQUENCES SOCIALES,CONSÉQUENCES ENVIRONNEMENTALES      0.000     0.000     0.000         6\n",
      "                                                                     Inconnue      0.000     0.000     0.000        42\n",
      "\n",
      "                                                                     accuracy                          0.646       285\n",
      "                                                                    macro avg      0.328     0.344     0.297       285\n",
      "                                                                 weighted avg      0.566     0.646     0.561       285\n",
      "\n",
      "Macro-F = 0.29661260802294426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "cv=StratifiedKFold(n_splits=10,shuffle=True,random_state=0)\n",
    "\n",
    "def eval(model,name):\n",
    "    pred=cross_val_predict(model,X_boost,y,cv=cv)\n",
    "    print(f\"\\n======== {name} ========\")\n",
    "    print(classification_report(y,pred,digits=3))\n",
    "    print(\"Macro-F =\",precision_recall_fscore_support(y,pred,average='macro')[2])\n",
    "\n",
    "eval(LinearSVC(class_weight=\"balanced\"),\"SVM optimized\")\n",
    "eval(RandomForestClassifier(n_estimators=500,class_weight=\"balanced\"),\"RF optimized\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b3fd46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
